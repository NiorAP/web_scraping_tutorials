{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "njbmJ4fFZRBY"
   },
   "source": [
    "# Python Web Scraping Tutorial #2: ใช้ Requests มาช่วย Pandas ดึงข้อมูล"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Nior Atthakorn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จาก[ตอนที่แล้ว](https://medium.com/@nioratthakorn/python-web-scraping-tutorial-1-9cba93ac2690) เราได้ใช้ [Pandas](https://pandas.pydata.org) ในการทำ Web Scraping มาแล้ว ซึ่งก็มีข้อจำกัดอยู่หลายอย่าง ไม่ว่าจะเป็นการที่ข้อมูลจะต้องเป็นตารางเท่านั้น หรือตัว url ที่จะมีตัวอักษรที่แปลกประหลาดหน่อย (อย่างเช่นตัวอักษรภาษาไทย) ไม่ได้เลย"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ในบทความนี้เราจึงจะใช้ [Requests](https://pypi.org/project/requests/) ซึ่งเป็น library สำหรับการส่ง http request อย่างง่าย มาช่วยแก้ปัญหาที่ตัว Pandas ไม่สามารถอ่าน url แปลกๆ ได้ จะมีวิธีการทำยังไง ก็อ่านต่อด้านล่างนี้เลย Let's Go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"center\">\n",
    "    <td>\n",
    "        <a href=\"https://github.com/NiorAP/web_scraping_tutorials/blob/master/Python%20Web%20Scraping%20Tutorial%20%232/Python%20Web%20Scraping%20Tutorial%20%232.ipynb\">\n",
    "            <img src=\"https://pngimg.com/uploads/github/github_PNG58.png\" width=\"100\"/>\n",
    "            <center>\n",
    "                ดูใน GitHub\n",
    "            </center>\n",
    "        </a>\n",
    "    </td>\n",
    "    <td>\n",
    "        <a href=\"https://colab.research.google.com/drive/1ymFoRjC8Fv4O4r8hq90az81weJCH9DA_\">\n",
    "            <img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\" width=\"100\"/>\n",
    "            <center>\n",
    "                ลองเล่นใน Google Colab\n",
    "            </center>\n",
    "        </a>\n",
    "    </td>\n",
    "    <td>\n",
    "        <a href=\"https://medium.com/@nioratthakorn/python-web-scraping-tutorial-2-7a8d09a36093\">\n",
    "            <img src=\"https://cdn4.iconfinder.com/data/icons/vector-brand-logos/40/Medium-512.png\"/ width=\"100\">\n",
    "            <center>\n",
    "                อ่านใน Medium\n",
    "            </center>\n",
    "        </a>\n",
    "    </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ก่อนหน้านี้](https://medium.com/@nioratthakorn/python-web-scraping-tutorial-1-9cba93ac2690)เราใช้แค่ function [read_html](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.read_html.html) ของ Pandas โดยใส่ url เข้าไป ก็สามารถทำการ Scrape ข้อมูลที่เราต้องการได้ทันที แต่ถ้า url ใช้ไม่ได้หล่ะ ?\n",
    "\n",
    "ถ้ายังจำกันได้[จากขั้นตอนที่ 3](https://medium.com/@nioratthakorn/python-web-scraping-tutorial-1-9cba93ac2690#b5fb) ใน[บทความที่แล้ว](https://medium.com/@nioratthakorn/python-web-scraping-tutorial-1-9cba93ac2690) ที่บอกไว้ว่าตัว `read_html` สามารถรับ parameter ได้หลายรูปแบบ โดยในบทความนี้เราจะส่ง HTML text ให้ `read_html` ดึงข้อมูลที่เป็นตารางที่เราต้องการจากหน้า website\n",
    "\n",
    "แล้วเราจะได้ HTML text มาได้ยังไง ? ก็แหงหล่ะครับ ดูจากชื่อบทความก็น่าจะพอเดาได้ไม่ยากนะครับ เราจะใช้ library ที่ชื่อ Requests มาดึงข้อมูล HTML จาก website นั่นเองงงง\n",
    "\n",
    "<i><center><b>ในเมื่อ Pandas ดึงข้อมูลจาก website ที่มี url แปลกๆ ไม่ได้ ก็ให้ Requests ดึงมาให้ แล้วให้ Pandas จัดการต่อ</b></center></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPEPdb4MaeLU"
   },
   "source": [
    "<i><b>ขั้นตอนที่ 1</b></i> ก็เหมือนๆ เดิมครับ `import` library ที่จะใช้ ในที่นี้จะใช้ 2 ตัว\n",
    "- Requests -> ดึงข้อมูลหน้า website\n",
    "- Pandas -> แปลงข้อมูลที่ได้มาเป็นตาราง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QG6rmBgG8Pni"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4KZj2Cuqdf7V"
   },
   "source": [
    "<i><b>ขั้นตอนที่ 2</b></i> ใส่ url ของ website ที่เราต้องการ scrape เหมือนเดิม ซึ่งจาก[บทความแรก](https://medium.com/@nioratthakorn/python-web-scraping-tutorial-1-9cba93ac2690) url ต้องเป็นภาษาอังกฤษเท่านั้น (ถ้า url มีภาษาไทย ใช้วิธีเดิมไม่ได้) แต่ในบทความนี้สามารถใช้ได้ ในที่นี้จะใช้ website [สถิติหวยย้อนหลัง 29 ปี](https://www.myhora.com/หวย/สถิติหวย-ย้อนหลัง-25-ปี.aspx?mode=year-range&value=29) ของ [myhora.com](https://www.myhora.com/) ต้องขออนุญาตและขอขอบคุณมา ณ ที่นี้ด้วยนะครับ -/\\\\-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.myhora.com/หวย/' \\\n",
    "    + 'สถิติหวย-ย้อนหลัง-29-ปี.aspx?mode=year-range&value=29'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url ยาว เลยเขียนแยกเป็น 2 ท่อนเหมือนเดิมจ้า"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "up_oq16cd1CP"
   },
   "source": [
    "<i><b>ขั้นตอนที่ 3</b></i> ให้เราใช้ function [`get`](https://requests.readthedocs.io/en/master/user/quickstart/#make-a-request) ของ Requests ในการดึงข้อมูลหน้า website จาก url ที่เราใส่"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "soMg8fT18ycP"
   },
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wYVn2y0TeT6T"
   },
   "source": [
    "<i><b>ขั้นตอนที่ 4</b></i> ให้เราใช้ function `read_html` ของ pandas โดยตัวอย่างที่แล้วเราใส่ url เป็น argument ซึ่งจะทำให้ตัว function ไปดึงข้อมูลทั้งหมดจาก website นั้นๆ แต่ในที่นี้เราใส่ข้อมูล HTML text เข้าไปเลย ตัว function `read_html` ก็จะ scan ดูทั้ง HTML ที่ใส่เข้าไป ว่ามีตารางอยู่ตรงไหนบ้าง แปลงแต่ละตารางเป็น [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) แล้วใส่ไว้ใน list ให้เราได้เหมือนเดิม สะดวกเกิ๊น"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UHpeIN2H9PKX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs = pd.read_html(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ตอนนี้ก็จบขั้นตอนการ scrape แล้ว มาลองดูผลลัพธ์กันสักหน่อย"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ywPf6mIKgiF9"
   },
   "source": [
    "ลองดูก่อนเหมือนเดิมว่าจำนวนตารางที่ได้ตรงกับในหน้า website ที่เราเห็นมั้ย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22365,
     "status": "ok",
     "timestamp": 1585578324064,
     "user": {
      "displayName": "Atthakorn Petchsod",
      "photoUrl": "",
      "userId": "05623350520098048905"
     },
     "user_tz": -420
    },
    "id": "OjOt5kt-AhaF",
    "outputId": "2a0021e5-373e-4623-ccfa-be15302929b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เจอตารางมากถึง 29 ตาราง แต่เอ๊ะ! ลองเลื่อนดูผ่านๆ ในหน้า website มันก็ดูไม่น่ามีถึง 29 ตารางนี่นา ทำไมมันออกมาตั้ง 29 ตาราง ?\n",
    "\n",
    "ถ้าคุณคิดแบบนี้ไม่ต้องตกใจไปครับ (เพราะตอนแรกผมก็คิดแบบนั้น) ในหน้า website เขามีบางตารางที่ (เหมือนกับ) ซ่อนอยู่ (แต่จริงๆ เขาไม่ได้ซ่อนน้า) ลองเลื่อนไปดูแถวๆ ด้านล่างของแต่ละกล่อง จะเจอปุ่มประมาณนี้\n",
    "\n",
    "![](https://github.com/NiorAP/web_scraping_tutorials/raw/master/Python%20Web%20Scraping%20Tutorial%20%232/Image-2-1.png)\n",
    "\n",
    "ลองกดดูซิ จะเป็นยังไงน้าาาา\n",
    "\n",
    "![](https://github.com/NiorAP/web_scraping_tutorials/raw/master/Python%20Web%20Scraping%20Tutorial%20%232/Image-2-2.png)\n",
    "\n",
    "นี่ไง มีตารางซ่อนอยู่ในนี้อีก ซึ่งถ้าเราลองกดดูทั้งหมดทั้งมวล แล้วลองนับตารางดู เราก็จะได้ 29 ตารางพอดิบพอดีเลย\n",
    "\n",
    "เนื่องจากใน website นี้มีตารางเยอะมาก ในที่นี้เลยขอดึงมาดูแค่ 2 ตาราง คือตารางแรกกับตารางสุดท้าย ว่าได้หน้าตาอย่างที่เราอยากได้มั้ย"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gGUooLZmglS5"
   },
   "source": [
    "เริ่มจากตารางแรกก่อนเลย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22359,
     "status": "ok",
     "timestamp": 1585578324064,
     "user": {
      "displayName": "Atthakorn Petchsod",
      "photoUrl": "",
      "userId": "05623350520098048905"
     },
     "user_tz": -420
    },
    "id": "k2ed0xTZZlWK",
    "outputId": "ba7de3f1-1372-41b8-fa55-8286700c478e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>หลัก</td>\n",
       "      <td>เลข0</td>\n",
       "      <td>เลข1</td>\n",
       "      <td>เลข2</td>\n",
       "      <td>เลข3</td>\n",
       "      <td>เลข4</td>\n",
       "      <td>เลข5</td>\n",
       "      <td>เลข6</td>\n",
       "      <td>เลข7</td>\n",
       "      <td>เลข8</td>\n",
       "      <td>เลข9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>สิบ</td>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "      <td>71</td>\n",
       "      <td>62</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>71</td>\n",
       "      <td>66</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>หน่วย</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "      <td>94</td>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "      <td>88</td>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>รวม</td>\n",
       "      <td>133</td>\n",
       "      <td>150</td>\n",
       "      <td>139</td>\n",
       "      <td>134</td>\n",
       "      <td>168</td>\n",
       "      <td>139</td>\n",
       "      <td>138</td>\n",
       "      <td>159</td>\n",
       "      <td>130</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     10\n",
       "0   หลัก  เลข0  เลข1  เลข2  เลข3  เลข4  เลข5  เลข6  เลข7  เลข8  เลข9\n",
       "1    สิบ    68    72    71    62    74    78    72    71    66    62\n",
       "2  หน่วย    65    78    68    72    94    61    66    88    64    40\n",
       "3    รวม   133   150   139   134   168   139   138   159   130   102"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "พอได้อยู่ อาจจะต้องจัดการอีกนิดนึง แต่ก็ถือว่าใช้ได้แล้ว"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "มาลองดูตารางสุดท้ายกันบ้าง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16 มีนาคม มี.ค. 2563 63 503446 46 446 77  258 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1 มีนาคม มี.ค. 2563 63 875938 38 938 98  294 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>16 กุมภาพันธ์ ก.พ. 2563 63 781403 03 403 94  5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1 กุมภาพันธ์ ก.พ. 2563 63 589227 27 227 06  25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17 มกราคม ม.ค. 2563 63 491774 74 774 68  004 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  16 มีนาคม มี.ค. 2563 63 503446 46 446 77  258 ...\n",
       "1  1 มีนาคม มี.ค. 2563 63 875938 38 938 98  294 3...\n",
       "2  16 กุมภาพันธ์ ก.พ. 2563 63 781403 03 403 94  5...\n",
       "3  1 กุมภาพันธ์ ก.พ. 2563 63 589227 27 227 06  25...\n",
       "4  17 มกราคม ม.ค. 2563 63 491774 74 774 68  004 1..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[-1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vzePNjKahBoo"
   },
   "source": [
    "<i>อ้าวเฮ้ย ไม่เหมือนที่คุยกันไว้นี่หน่า</i>\n",
    "\n",
    "จากด้านบนจะเห็นว่า เราได้ตารางที่เราอยากได้แล้ว แต่อยู่ในรูปแบบที่เรายังไม่ต้องการ ข้อมูลทั้งหมดอยู่ใน column เดียวกัน เราต้องการ split ออกจากกัน\n",
    "\n",
    "ในส่วนนี้เป็นการใช้งาน Pandas ในการจัดการข้อมูลที่มี ไม่เกี่ยวข้องกับการ scrape แล้ว แต่ก็มาลองทำกันดูสักหน่อยจะเป็นไรไป เนอะๆๆๆๆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8RMxavP9YVv"
   },
   "outputs": [],
   "source": [
    "df = dfs[-1][0].str.split(expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โอ้โห อะไรไม่รู้ยั้วเยี๊ยเต็มไปหมดเลย ลองค่อยๆ เจาะดูกันทีละส่วนครับ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "dfs[-1]\n",
    "```\n",
    "ส่วนแรกนี้คือการเลือกตารางสุดท้ายออกมาจากผลลัพธ์การ scrape ซึ่งก็คือตารางสุดยุ่งเหยิงที่เราจะเอามาทำการแปลงโฉมนั่นเอง (โดยตารางเป็นประเภท Pandas DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "dfs[-1][0]\n",
    "```\n",
    "หลังจากเลือกตารางแล้ว ก็มาเลือก column อีกที เนื่องจากคำสั่งที่เราจะใช้ต่อไปนี้เป็นคำสั่งที่ใช้กับ [Pandas Series](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html) เท่านั้น"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "dfs[-1][0].str\n",
    "```\n",
    "ตัว [`.str`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.html) นี้ทำให้เราสามารถใช้ method ที่คล้ายๆ ว่าจะเป็น [string method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.split.htmls) กับ Pandas Series ได้"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "dfs[-1][0].str.split(expand=True)\n",
    "```\n",
    "ส่วนสุดท้ายนี้ก็คือ method [`split`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.split.html) ที่จะตัดแบ่ง string ตามตัวอักษรที่เรากำหนดไว้ (ในที่นี้ไม่ได้กำหนดไว้ method ก็จะไปดึงค่า default  นั่นคือ space \" \" มาใช้ในการแบ่ง) พร้อมทั้งใส่ parameter `expand=True` เป็นการบอกให้กระจายผลลัพธ์ที่ได้จากการแบ่งเป็น column หลายๆ อัน"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IM4MKQilii85"
   },
   "source": [
    "ดูสภาพหลังแปลงแล้ว"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22351,
     "status": "ok",
     "timestamp": 1585578324065,
     "user": {
      "displayName": "Atthakorn Petchsod",
      "photoUrl": "",
      "userId": "05623350520098048905"
     },
     "user_tz": -420
    },
    "id": "24gQ8yZtEi_v",
    "outputId": "56913c39-c51e-4b22-a44a-d116b11dd86b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>มีนาคม</td>\n",
       "      <td>มี.ค.</td>\n",
       "      <td>2563</td>\n",
       "      <td>63</td>\n",
       "      <td>503446</td>\n",
       "      <td>46</td>\n",
       "      <td>446</td>\n",
       "      <td>77</td>\n",
       "      <td>258</td>\n",
       "      <td>726</td>\n",
       "      <td>404</td>\n",
       "      <td>661</td>\n",
       "      <td>77</td>\n",
       "      <td>258</td>\n",
       "      <td>726</td>\n",
       "      <td>404</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>มีนาคม</td>\n",
       "      <td>มี.ค.</td>\n",
       "      <td>2563</td>\n",
       "      <td>63</td>\n",
       "      <td>875938</td>\n",
       "      <td>38</td>\n",
       "      <td>938</td>\n",
       "      <td>98</td>\n",
       "      <td>294</td>\n",
       "      <td>328</td>\n",
       "      <td>597</td>\n",
       "      <td>780</td>\n",
       "      <td>98</td>\n",
       "      <td>294</td>\n",
       "      <td>328</td>\n",
       "      <td>597</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>กุมภาพันธ์</td>\n",
       "      <td>ก.พ.</td>\n",
       "      <td>2563</td>\n",
       "      <td>63</td>\n",
       "      <td>781403</td>\n",
       "      <td>03</td>\n",
       "      <td>403</td>\n",
       "      <td>94</td>\n",
       "      <td>515</td>\n",
       "      <td>952</td>\n",
       "      <td>030</td>\n",
       "      <td>918</td>\n",
       "      <td>94</td>\n",
       "      <td>515</td>\n",
       "      <td>952</td>\n",
       "      <td>030</td>\n",
       "      <td>918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>กุมภาพันธ์</td>\n",
       "      <td>ก.พ.</td>\n",
       "      <td>2563</td>\n",
       "      <td>63</td>\n",
       "      <td>589227</td>\n",
       "      <td>27</td>\n",
       "      <td>227</td>\n",
       "      <td>06</td>\n",
       "      <td>259</td>\n",
       "      <td>552</td>\n",
       "      <td>375</td>\n",
       "      <td>927</td>\n",
       "      <td>06</td>\n",
       "      <td>259</td>\n",
       "      <td>552</td>\n",
       "      <td>375</td>\n",
       "      <td>927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>มกราคม</td>\n",
       "      <td>ม.ค.</td>\n",
       "      <td>2563</td>\n",
       "      <td>63</td>\n",
       "      <td>491774</td>\n",
       "      <td>74</td>\n",
       "      <td>774</td>\n",
       "      <td>68</td>\n",
       "      <td>004</td>\n",
       "      <td>132</td>\n",
       "      <td>379</td>\n",
       "      <td>595</td>\n",
       "      <td>68</td>\n",
       "      <td>004</td>\n",
       "      <td>132</td>\n",
       "      <td>379</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0           1      2     3   4       5   6    7   8    9   10   11   12  \\\n",
       "0  16      มีนาคม  มี.ค.  2563  63  503446  46  446  77  258  726  404  661   \n",
       "1   1      มีนาคม  มี.ค.  2563  63  875938  38  938  98  294  328  597  780   \n",
       "2  16  กุมภาพันธ์   ก.พ.  2563  63  781403  03  403  94  515  952  030  918   \n",
       "3   1  กุมภาพันธ์   ก.พ.  2563  63  589227  27  227  06  259  552  375  927   \n",
       "4  17      มกราคม   ม.ค.  2563  63  491774  74  774  68  004  132  379  595   \n",
       "\n",
       "   13   14   15   16   17  \n",
       "0  77  258  726  404  661  \n",
       "1  98  294  328  597  780  \n",
       "2  94  515  952  030  918  \n",
       "3  06  259  552  375  927  \n",
       "4  68  004  132  379  595  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สวยงามตามท้องเรื่องงงง"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เป็นไงกันบ้างครับกับการใช้ Requests มาช่วย Pandas ทำ Web Scraping ง่ายเหมือนเดิมใช่ไหมหล่ะครับ แต่ก็ยังมีเงื่อนไขในการใช้งานอยู่อีกพอสมควร\n",
    "\n",
    "ด้วยข้อจำกัดใหญ่ที่ข้อมูลต้องเป็นตารางเท่านั้น แล้วถ้าข้อมูลไม่ใช่ตารางหล่ะ ? เราจะทำยังไงต่อ ใช้เครื่องมืออะไร ติดตามได้ในตอนต่อๆ ไปนะครับ\n",
    "\n",
    "ส่วนใครยังไม่ได้อ่านตอนแรก หรืออ่านแล้วลืมแล้วสามารถย้อนอ่านตอนแรกได้ที่นี่เลย:  \n",
    "[Python Web Scraping Tutorial #1: ใช้ Pandas ดึงข้อมูลที่เป็นตารางจากหน้า Website](https://medium.com/@nioratthakorn/python-web-scraping-tutorial-1-9cba93ac2690)\n",
    "\n",
    "สำหรับวันนี้ก็ แค่นี้แหละครับ บายยยย"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMmkajdonDvIdS9QUGCfRh8",
   "collapsed_sections": [],
   "name": "Scrape#2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
